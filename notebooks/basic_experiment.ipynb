{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "PROJECT_PATH = os.path.dirname(os.getcwd())\n",
    "sys.path.append(PROJECT_PATH)\n",
    "sys.path.append(os.getcwd())\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Dict\n",
    "from lsbd_vae.models.architectures import get_encoder_decoder\n",
    "from lsbd_vae.data_utils.data_loader import load_factor_data\n",
    "from experiments.configs.paper_dataset_parameters import return_data_parameters\n",
    "from lsbd_vae.data_utils.factor_dataset import FactorImageDataset\n",
    "from lsbd_vae.utils.model_utils import get_ls_list, get_autoencoder_model\n",
    "from lsbd_vae.utils.plotting import plot_subset, plot_objects_pca, plot_data_examples_grid, image_scatter\n",
    "from lsbd_vae.metrics.dlsbd_metric import create_combinations_omega_values_range, dlsbd\n",
    "\n",
    "TORUS_DATASETS = {\"arrow\", \"pixel4\", \"modelnet_colors\", \"pixel8\", \"pixel16\"}\n",
    "CYLINDER_DATASETS = {\"coil100\", \"modelnet40_airplanes\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset Loading\n",
    "Images in the datasets are loaded into instances of a class called FactorImageDataset which has methods and properties that take into account the underlying subgroup structure of the data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the name of the dataset\n",
    "dataset: str = \"modelnet40_airplanes\"\n",
    "# Get the parameters used to load the data\n",
    "data_parameters: Dict = return_data_parameters(dataset)\n",
    "# Use util function to load the data. The data is loaded into an instance of the class FactorImageDataset\n",
    "data_class: FactorImageDataset = load_factor_data(**data_parameters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset Images\n",
    "The dataset class contains a property called *images* with all available data created from the actions of the group\n",
    " $G = G_1\\times G_2\\times \\cdot G_K$ where each $G_k$ with $k\\in\\{1,2,\\ldots, K\\}$ is a subgroup of $G$.\n",
    "In our experiment we usually use $K=2$ subgroups at most.\n",
    "The total number of images available is $N = \\prod_{k=1}^K|G_K|$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Shape of the dataset images {} with: \\n- {} elements corresponding to subgroup 1 \\n- {} elements corresponding to sugbroup 2\"\n",
    "    \" \\n- {} height \\n- {} width  \\n- {} channels \\nTotal data {} N =  images\".format(data_class.images.shape,\n",
    "                                                                                      *data_class.images.shape,\n",
    "                                                                                      np.product(\n",
    "                                                                                          data_class.images.shape[\n",
    "                                                                                          :-3])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot examples\n",
    "We can inspect the data that we have loaded. We will visualize it in a grid of images. In this grid along the vertical direction, for a fixed column, only a single factor changes through the actions of the first subgroup $G_1$. In the case of the arrow dataset we see that the arrow rotates counter-clockwise.\n",
    "Along the horizontal direction, for a fixed row, we can see the actions of the second subgroup $G_2$ (periodic change in the colour).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, _ = plot_data_examples_grid(7, data_class, \"binary_r\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset Factors\n",
    "The true factor values that describe each of the images are stored in the *factor_mesh* property."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Names of the underlying factors {data_class.factor_names}\")\n",
    "print(f\"Factor mesh shape {data_class.factor_mesh.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Separate dataset\n",
    "\n",
    "We will be training an LSBDVAE model in a semi-supervised manner using known information about the underlying subgroup actions.\n",
    "To do so, we will need to split the dataset into two: a transformation-labelled dataset and transformation-unlabelled dataset.\n",
    "\n",
    "### Transformation Labelled Dataset\n",
    "The dataset is organized into $N'$ sets, each set has $M$ images $\\{x_m\\}_{m=1}^M$ and the corresponding labels representing the group elements $\\{g_m\\}_{m=1}^M$.\n",
    "Each datapoint in the set can be expressed  $x_m = g_m\\cdot x_1$. The images are organized into an array of shape (N', M, image_height, image_width, channels) while the\n",
    "group elements are organized into a list of subgroup transformation labels \\[subgroup1, subgroup2,...\\]. where each subgroup array has shape (N', M).\n",
    "\n",
    "In the case of cylinder datasets the transformation labels of subgroup1 would correspond to the transformations describing changes from one object to another.\n",
    "However, these have no group structure. Therefore, the labels of subgroup1 for cylinder datasets are all zeroes.\n",
    "\n",
    "### Unlabelled Dataset\n",
    "This dataset consists of the remaining images from the dataset organized into the shape of the data is (N-N', 1, image_height, image_width, channels).\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_labelled: int = 256  # Number N' of sets to be formed.\n",
    "m_group: int = 6  # Number M of images per group\n",
    "n_groups_per_object: int = 3 # Number of groups selected to be labelled per object for CYLINDER datasets\n",
    "\n",
    "\n",
    "if dataset in TORUS_DATASETS:\n",
    "    x_l, x_l_transformations, x_u = data_class.setup_torus_dataset_labelled_groups(n_labelled, m_group)\n",
    "elif dataset in CYLINDER_DATASETS:\n",
    "    x_l, x_l_transformations, x_u = data_class.setup_cylinder_dataset_labelled_groups(n_groups_per_object, m_group)\n",
    "else:\n",
    "    raise Exception(f\"Dataset {dataset} is not within the list of cylinder or torus datasets\")\n",
    "\n",
    "print(\n",
    "    f\"- Unlabelled dataset shape {x_u.shape} \\n- Labelled dataset shape {x_l.shape}\\n- Subgroup 1 labels shape {x_l_transformations[0].shape}\\n- Subgroup 2 labels shape {x_l_transformations[1].shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training an LSBDVAE\n",
    "To train an LSBDVAE model we need to provide two key components:\n",
    "- A list of **LatentSpace** class instances that defines each of the subspaces of the latent space\n",
    "- **Neural Network** encoder and decoder backbones.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the latent spaces\n",
    "The LSBD can take multiple latent spaces with different geometry. In the case of the datasets where the underlying factors\n",
    "have generated from a group $G = \\mathrm{SO}(2)\\times \\mathrm{SO}(2)$ such as the square, arrow and modelnet_colors, we use\n",
    "a latent space consisting of two circles i.e. $Z = S^1\\times S^1$ which corresponds to a torus.\n",
    "\n",
    "In the case of data consisting of multiple objects subject to $G = \\mathrm{SO}(2)$ rotations we use a latent space cylindrical latent\n",
    "space $Z = S^1\\times \\mathbb{R}^5$ where the circle $S^1$ is used to represent the rotations and the Euclidean space $\\mathbb{R}^5$ is\n",
    "used to represent the object identities."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if dataset in TORUS_DATASETS:\n",
    "    latent_parameters = {\n",
    "        \"latent_types\": [\"s\", \"s\"],\n",
    "        \"latent_dims\": [1, 1],\n",
    "        \"kl_weights\": None,\n",
    "        \"kwargs_list\": [{\"log_t_limit\": (-10, -5), \"dist_weight\": 1}, {\"log_t_limit\": (-10, -5), \"dist_weight\": 1}]\n",
    "\n",
    "    }\n",
    "elif dataset in CYLINDER_DATASETS:\n",
    "    latent_parameters = {\n",
    "        \"latent_types\": [\"s\", \"e\"],\n",
    "        \"latent_dims\": [1, 5],\n",
    "        \"kl_weights\": None,\n",
    "        \"kwargs_list\": [{\"log_t_limit\": (-10, -5)}, {}]\n",
    "    }\n",
    "else:\n",
    "    raise Exception(f\"Dataset {dataset} is not within the list of cylinder or torus datasets\")\n",
    "\n",
    "ls_list = get_ls_list(**latent_parameters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the model architecture\n",
    "We can define the model's neural network architecture for the encoder and decoder. The encoder and decoder are instances\n",
    "of the tf.keras.models.Model class. The encoder can be substituted with any neural network that receives an image of the\n",
    "correct size and produces a flat tensor of any dimension. The decoder can be substituted with any neural network that\n",
    "receives an input with the same dimension as the total dimension of the latent space and produces an image of the appropriate\n",
    "size.\n",
    "\n",
    "In our experiments we use the same architectures which can be obtained with the helper function get_encoder_decoder\n",
    "receiving the appropriate parameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if dataset in TORUS_DATASETS:\n",
    "    architecture_params = {\n",
    "        \"latent_dim\": 4,\n",
    "        \"architecture\": \"dislib\",\n",
    "        \"image_shape\": data_class.image_shape\n",
    "    }\n",
    "elif dataset in CYLINDER_DATASETS:\n",
    "    architecture_params = {\n",
    "        \"latent_dim\": 7,\n",
    "        \"architecture\": \"dislib\",\n",
    "        \"image_shape\": data_class.image_shape\n",
    "    }\n",
    "else:\n",
    "    raise Exception(f\"Dataset {dataset} is not within the list of cylinder or torus datasets\")\n",
    "encoder_backbone, decoder_backbone = get_encoder_decoder(**architecture_params)\n",
    "print(\"Encoder architecture\")\n",
    "encoder_backbone.summary()\n",
    "print(\"Decoder architecture\")\n",
    "decoder_backbone.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the model\n",
    "Now that we have both the list of latent spaces and the neural network backbones we can define our LSBDVAE. We need to\n",
    "specify the number of datapoints that each labelled group of data will have. Under the hood the LSBDVAE has two models\n",
    "an unsupervised DiffusionVAE model and a supervised model. Both share the same backbone neural networks and are optimized\n",
    "jointly in each of the training steps."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_parameters = {\n",
    "    \"model_type\": \"LSBDVAE\",\n",
    "    \"n_transforms\": n_groups_per_object,\n",
    "    \"input_shape\": data_class.image_shape\n",
    "}\n",
    "model_class = get_autoencoder_model(latent_spaces=ls_list, encoder_backbones=[encoder_backbone],\n",
    "                                    decoder_backbone=decoder_backbone,\n",
    "                                    **model_parameters)\n",
    "model_class.compile(optimizer=\"adam\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the model\n",
    "The LSBDVAE model has a method for training in a semi-supervised manner. This method can be used to train with different\n",
    "degrees of supervision and it automatically detects how to train depending on whether an empty list for the labelled or\n",
    "unlabelled data is provided. During each training step the unsupervised and supervised parts of the LSBDVAE are updated\n",
    "using the corresponding signals from the labelled and unlabelled dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs: int = 11\n",
    "batch_size: int = 100\n",
    "# Setup eager execution for training\n",
    "tf.config.run_functions_eagerly(True)\n",
    "model_class.fit_semi_supervised(x_l, x_l_transformations, x_u, epochs=epochs, batch_size=batch_size)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation\n",
    "Now that we have trained the LSBDVAE we can evaluate the resulting model. First of all, we will assess the quality of the\n",
    "reconstructions that the model creates to see whether the model is capable of reproducing the input data. For this, we\n",
    "can use the method encode_images which takes images with shape (n_images, image_width, image_height, channels) and produces\n",
    "a list of vectors corresponding to the embeddings for each LatentSpace corresponding to the location parameter of the\n",
    "encoding distributions. We can concatenate the embeddings to obtain the latent vectors which can be used for decoding.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoded_list = model_class.encode_images(data_class.flat_images)\n",
    "scale_list = model_class.encode_images_scale(data_class.flat_images)\n",
    "latent_reps = np.concatenate(encoded_list, axis=-1)\n",
    "print(\"Latent representation shape\", np.expand_dims(latent_reps, axis=1).shape)\n",
    "\n",
    "reconstructions = model_class.u_lsbd.decoder_unlabeled.predict(np.expand_dims(latent_reps, axis=1), batch_size=32)[:, 0,\n",
    "                  ...]\n",
    "latent_reps = latent_reps.reshape((*data_class.factors_shape, latent_reps.shape[-1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting\n",
    "Let's plot some random images and their reconstructions. The original images are on the top row while the reconstructions are on the bottom."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_size = 20  # sample size\n",
    "print(\"Flat image shape\", data_class.flat_images.shape)\n",
    "print(\"Reconstructions shape\", reconstructions.shape)\n",
    "x_and_rec = np.stack([data_class.flat_images, reconstructions], axis=1)\n",
    "indices = np.random.choice(len(x_and_rec), size=sample_size, replace=False)\n",
    "x_sample = np.moveaxis(x_and_rec[indices], 0, 1)\n",
    "print(\"Reconstructions shape\", x_sample.shape)\n",
    "plot_subset(x_sample);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PCA Projections\n",
    "We can now visualize the  plots corresponding to the projected embeddings in a 2D space. Each image is used to show its position in the scatter plot."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for num_encoding, encoding in enumerate(encoded_list):\n",
    "    print(\"Encodings shape\", encoding.shape)\n",
    "    fig, ax = plot_objects_pca(data_class.flat_images, encoding, zoom=0.3)\n",
    "    ax.grid()\n",
    "    plt.show();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot the unwrapped embeddings\n",
    "In the case of datasets with an underlying toroidal structure we can *unwrap* the torus to show the embedded data on the\n",
    "hyper-dimensional latent space. Since we have a latent space $Z = S^1\\times S^1$ consisting of two circles we can plot\n",
    "the corresponding angle values for each of the embeddings."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if dataset in TORUS_DATASETS:\n",
    "    print(\"Plot unwrapped torus\")\n",
    "    # Identify the angles corresponding to the encoding embeddings in each of the circles of the latent space\n",
    "    unwrapped_angles = np.stack([np.arctan2(encoding[:, 1], encoding[:, 0]) for encoding in encoded_list], axis=-1)\n",
    "    fig, ax = plot_objects_pca(data_class.flat_images, unwrapped_angles, zoom=0.3)\n",
    "    ax.grid()\n",
    "    ax.set_title(\"Unwrapped torus\", fontsize = 25)\n",
    "    ax.set_xlabel(\"Angle1\", fontsize = 25)\n",
    "    ax.set_xlabel(\"Angle2\", fontsize = 25)\n",
    "    # Set x,y angle limits to [-pi,pi]\n",
    "    ax.set_xlim([-np.pi, np.pi])\n",
    "    ax.set_ylim([-np.pi, np.pi])\n",
    "    plt.show();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculate LSBD Metric\n",
    "Finally, we can calculate the $\\mathcal{D}_\\mathrm{LSBD}$ metric. We need to define a search space of omega values to\n",
    "find the most appropriate parameters that define the group action that best fits our encoded data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if dataset in TORUS_DATASETS:\n",
    "    factor_manifold = \"torus\"\n",
    "elif dataset in CYLINDER_DATASETS:\n",
    "    factor_manifold = \"cylinder\"\n",
    "else:\n",
    "    Exception(f\"Dataset {dataset} is not within the list of cylinder or torus datasets\")\n",
    "omega_values = create_combinations_omega_values_range(start_value=-10, end_value=10)\n",
    "dlsbd_value, omega_best = dlsbd(latent_reps, omega_values, be_verbose=False, factor_manifold=\"torus\")\n",
    "print(f\"Metric value {dlsbd_value} obtained by the model\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8079af8c",
   "language": "python",
   "display_name": "PyCharm (tfmvae)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}